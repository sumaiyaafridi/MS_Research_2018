{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy \n",
    "numpy.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, MaxPooling2D, Dropout\n",
    "from keras.layers import Conv2D, Embedding\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=28 #128\n",
    "#embedding_dims=3\n",
    "num_classes=37 #37 #1227 #40499 #4\n",
    "epochs=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# num_images=100\n",
    "# dim=(100,100,1)\n",
    "# x=numpy.zeros((num_images, 100,100,1))\n",
    "# for fol in classes:\n",
    "#     imgfiles=os.listdir(path+u'\\\\'+fol);\n",
    "#     for i, img in enumerate(imgfiles):\n",
    "#         im=Image.open(path+'\\\\'+fol+'\\\\'+img)\n",
    "#         x[i]=numpy.asarray(im)/255\n",
    "    \n",
    "# print (x.shape)\n",
    "\n",
    "\n",
    "os.chdir(\"E:\");\n",
    "path=\"E:/Dummy/NN2\";\n",
    "# path=\"newdataset/1\";\n",
    "# path=\"newdataset/2\";\n",
    "# path=\"Dataset-3characters-only - CC -DC\";\n",
    "# path=\"Dataset_3_MoreFonts/1\";\n",
    "classes=os.listdir(path)\n",
    "x=[]#Datapoints 830\n",
    "y=[]#labels 3\n",
    "for fol in classes:\n",
    "    #print (fol)\n",
    "    imgfiles=os.listdir(path+u'\\\\'+fol);\n",
    "    #print (imgfiles)\n",
    "    for img in imgfiles:\n",
    "       # print (img)\n",
    "        #im=Image.open(path+u'\\\\'+fol+u'\\\\'+img);\n",
    "        im=mpimg.imread(path+u'\\\\'+fol+u'\\\\'+img);\n",
    "        #im.show()\n",
    "        #im=numpy.asarray(im)/255;\n",
    "       # print(im)\n",
    "        x.append(im)\n",
    "        y.append(fol)\n",
    "x=numpy.array(x)\n",
    "#print (x)\n",
    "y=numpy.array(y)\n",
    "#print(y)\n",
    "# numpy.savez('C:/Dataset_Final(March)/xlevel0',x)\n",
    "# numpy.savez('C:/Dataset_Final(March)/ylevel0',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x=numpy.load('C:/Dataset_Final(March)/xlevel0.npz')\n",
    "# x=x['arr_0']\n",
    "# print (x.shape)\n",
    "# y=numpy.load('C:/Dataset_Final(March)/xlevel0.npz')\n",
    "# y=y['arr_0']\n",
    "# print (y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HDF5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 100)\n",
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "#x=keras.utils.HDF5Matrix('Dataset_Final(March)/One.hdf5',x)\n",
    "#model.predict(x)\n",
    "x=x.reshape((-1,100,100,1))\n",
    "#print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=x.shape[0]\n",
    "randomize=numpy.arange(n)\n",
    "numpy.random.shuffle(randomize)\n",
    "randomize\n",
    "x=x[randomize]\n",
    "y=y[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 100, 100, 1)\n",
      "(96,)\n",
      "(48, 100, 100, 1)\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "test_split=round(n*2/3)\n",
    "x_train=x[:test_split]\n",
    "y_train=y[:test_split]\n",
    "x_test=x[test_split:]\n",
    "y_test=y[test_split:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "#y_train[:4]\n",
    "\n",
    "\n",
    "#print (class_weight)\n",
    "#print (class_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    " featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "48\n",
      "(96, 100, 100, 1)\n",
      "(48, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "#x_train=x_train.reshape((-1,100,100,1))\n",
    "#x_test=x_test.reshape(-1,100,100,1)\n",
    "\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "\n",
    "x_train/=255\n",
    "x_test/=255\n",
    "#plt.imshow(x_train[0])\n",
    "\n",
    "print(x_train.shape[0])\n",
    "print(x_test.shape[0])\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(y_train)\n",
    "# y_train= encoder.transform(y_train)\n",
    "# y_test= encoder.transform(y_test)\n",
    "\n",
    "# class_weight_list = compute_class_weight('balanced', numpy.unique(y_train), y_train)\n",
    "# class_weight = dict(zip(numpy.unique(y_train), class_weight_list))\n",
    "# print (class_weight)\n",
    "\n",
    "y_train=keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[:4]  \n",
    "#print (y_train.shape)\n",
    "\n",
    "#class_weight = class_weight.compute_class_weight('balanced', numpy.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs=Input(shape=(100,100,1))\n",
    "\n",
    "# x=Conv2D(32,(32,32), padding='same')(inputs)\n",
    "# x=LeakyReLU(alpha=0.1)(x) \n",
    "# #x=PReLU(alpha_initializer=\"zero\")(x) \n",
    "# #x=Activation('Relu')(x)\n",
    "# #x=ELU(alpha=1.0)(x) \n",
    "# x=Conv2D(16,(12,12))(x)\n",
    "# x=LeakyReLU(alpha=0.1)(x)\n",
    "# #x=PReLU(alpha_initializer=\"zero\")(x) \n",
    "# #x=ELU(alpha=1.0)(x) \n",
    "# x=Conv2D(8,(3,3))(x)\n",
    "# x=LeakyReLU(alpha=0.1)(x)\n",
    "# #x=PReLU(alpha_initializer=\"zero\")(x) \n",
    "# #x=Activation('Relu')(x)\n",
    "# #x=ELU(alpha=1.0)(x) \n",
    "# x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "# x=Dropout(0.2)(x)\n",
    "# x=Flatten()(x)\n",
    "# x=Dense(num_classes)(x)\n",
    "# #x=Activation('softmax')(x)\n",
    "# output=Activation('softmax')(x)\n",
    "# model=Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "x=LeakyReLU(alpha=0.1)(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Conv2D(8, (3, 3), padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.1)(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(num_classes)(x)\n",
    "x=LeakyReLU(alpha=0.1)(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(num_classes)(x)\n",
    "output=Activation('softmax')(x)\n",
    "model=Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=(100, 100, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(6, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(6, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs=Input(shape=(100,100,1))\n",
    "\n",
    "# x=Conv2D(16,(3,3), padding='same')(inputs)\n",
    "# x=Activation('relu')(x)\n",
    "# x=Conv2D(8,(3,3))(x)\n",
    "# x=Activation('relu')(x)\n",
    "# x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "# x=Dropout(0.2)(x)\n",
    "# x=Flatten()(x)\n",
    "# x=Dense(num_classes)(x)\n",
    "# #x=Activation('softmax')(x)\n",
    "# output=Activation('softmax')(x)\n",
    "# model=Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 50, 50, 8)         2312      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 37)                185037    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 37)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 37)                1406      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 189,075\n",
      "Trainable params: 189,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt=keras.optimizers.rmsprop(lr=0.0000001,decay=1e-6 )\n",
    "#opt=keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#opt=keras.optimizers.Adamax(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 48 samples\n",
      "Epoch 1/22\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00001: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 1-0.08.hdf5\n",
      "Epoch 2/22\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00002: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 2-0.08.hdf5\n",
      "Epoch 3/22\n",
      "96/96 [==============================] - 2s 19ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00003: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 3-0.08.hdf5\n",
      "Epoch 4/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00004: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 4-0.08.hdf5\n",
      "Epoch 5/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00005: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 5-0.08.hdf5\n",
      "Epoch 6/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00006: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 6-0.08.hdf5\n",
      "Epoch 7/22\n",
      "96/96 [==============================] - 2s 22ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00007: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 7-0.08.hdf5\n",
      "Epoch 8/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0104 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00008: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 8-0.08.hdf5\n",
      "Epoch 9/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00009: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement- 9-0.08.hdf5\n",
      "Epoch 10/22\n",
      "96/96 [==============================] - 2s 22ms/step - loss: 3.6109 - acc: 0.0417 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00010: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-10-0.08.hdf5\n",
      "Epoch 11/22\n",
      "96/96 [==============================] - 2s 22ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00011: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-11-0.08.hdf5\n",
      "Epoch 12/22\n",
      "96/96 [==============================] - 2s 23ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00012: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-12-0.08.hdf5\n",
      "Epoch 13/22\n",
      "96/96 [==============================] - 2s 25ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00013: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-13-0.08.hdf5\n",
      "Epoch 14/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0313 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00014: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-14-0.08.hdf5\n",
      "Epoch 15/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00015: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-15-0.08.hdf5\n",
      "Epoch 16/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0104 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00016: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-16-0.08.hdf5\n",
      "Epoch 17/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0208 - val_loss: 3.6109 - val_acc: 0.1042\n",
      "\n",
      "Epoch 00017: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-17-0.10.hdf5\n",
      "Epoch 18/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0521 - val_loss: 3.6109 - val_acc: 0.1042\n",
      "\n",
      "Epoch 00018: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-18-0.10.hdf5\n",
      "Epoch 19/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0417 - val_loss: 3.6109 - val_acc: 0.1042\n",
      "\n",
      "Epoch 00019: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-19-0.10.hdf5\n",
      "Epoch 20/22\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 3.6109 - acc: 0.0417 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00020: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-20-0.08.hdf5\n",
      "Epoch 21/22\n",
      "96/96 [==============================] - 2s 22ms/step - loss: 3.6109 - acc: 0.0417 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00021: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-21-0.08.hdf5\n",
      "Epoch 22/22\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 3.6109 - acc: 0.0417 - val_loss: 3.6109 - val_acc: 0.0833\n",
      "\n",
      "Epoch 00022: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-22-0.08.hdf5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath='E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_22/weights-improvement-{epoch:2d}-{val_acc:.2f}.hdf5'\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
    "hist=model.fit(x_train, y_train, \n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_test),\n",
    "               callbacks=[checkpoint]\n",
    "               #class_weight=class_weight\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for e in range(epochs):\n",
    "#     print('Epoch', e)\n",
    "#     batches = 0\n",
    "#     for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "#         model.fit(x_batch, y_batch)\n",
    "#         batches += 1\n",
    "#         if batches >= len(x_train) / 32:\n",
    "#             # we need to break the loop by hand because\n",
    "#             # the generator loops indefinitely\n",
    "#             break\n",
    "# hist=model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                batch_size=batch_size),\n",
    "#                epochs=epochs,\n",
    "#                validation_data=(x_test, y_test),\n",
    "#                callbacks=[checkpoint]\n",
    "#                #workers=4\n",
    "#                #class_weight=class_weight\n",
    "#                )\n",
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=True,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "\n",
    "#     # Compute quantities required for feature-wise normalization\n",
    "#     # (std, mean, and principal components if ZCA whitening is applied).\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "#     # Fit the model on the batches generated by datagen.flow().\n",
    "# model.fit_generator(datagen.flow(x_train, y_train,\n",
    "#                                      batch_size=batch_size),\n",
    "#                         epochs=epochs,\n",
    "#                         callbacks=[checkpoint],\n",
    "#                         validation_data=(x_test, y_test),\n",
    "#                         workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6109507878621421"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 3 and 64. Shapes are [3,3,1,32] and [64,1,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,1,32], [64,1,3,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 64. Shapes are [3,3,1,32] and [64,1,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,1,32], [64,1,3,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-6a1cbb6ca6d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/Dataset_Final(March)/Checkpoints/Level_1/weights/weights-improvement- 1-0.00.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   2654\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[1;32m-> 2656\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   2657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   3380\u001b[0m                              ' elements.')\n\u001b[0;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3382\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2366\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2367\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2368\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2369\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \"\"\"\n\u001b[1;32m--> 599\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    278\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    279\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    281\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     60\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3271\u001b[0m         op_def=op_def)\n\u001b[0;32m   3272\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3273\u001b[1;33m                            compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3311\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3313\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3314\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3315\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2499\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2500\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2472\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2474\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2475\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2404\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 64. Shapes are [3,3,1,32] and [64,1,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,1,32], [64,1,3,3]."
     ]
    }
   ],
   "source": [
    "model.load_weights(\"E:/Dataset_Final(March)/Checkpoints/Level_1/weights/weights-improvement- 1-0.00.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22235/22235 [==============================] - 113s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6165685004964956"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043130200134922421"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02702772  0.02702761  0.02702937 ...,  0.0270265   0.02702716\n",
      "   0.02701131]\n",
      " [ 0.02702774  0.02702763  0.02702942 ...,  0.02702652  0.02702705\n",
      "   0.02701133]\n",
      " [ 0.02702777  0.02702764  0.02702945 ...,  0.02702654  0.02702708\n",
      "   0.0270113 ]\n",
      " ..., \n",
      " [ 0.02702778  0.02702762  0.02702943 ...,  0.02702654  0.0270271\n",
      "   0.02701128]\n",
      " [ 0.02702782  0.02702762  0.02702936 ...,  0.02702655  0.02702713\n",
      "   0.02701133]\n",
      " [ 0.0270278   0.02702769  0.02702937 ...,  0.02702658  0.02702709\n",
      "   0.02701137]]\n",
      "[26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)# for dataset of 2 characters\n",
    "print (y_pred)\n",
    "y_pred=numpy.argmax(y_pred, axis=1)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02702699  0.02702716  0.02702824 ...,  0.0270266   0.02702733\n",
      "   0.0270237 ]\n",
      " [ 0.02702705  0.02702716  0.0270283  ...,  0.0270266   0.02702722\n",
      "   0.02702371]\n",
      " [ 0.0270271   0.02702715  0.02702834 ...,  0.02702663  0.02702729\n",
      "   0.0270237 ]\n",
      " ..., \n",
      " [ 0.02702711  0.02702713  0.02702834 ...,  0.02702664  0.02702732\n",
      "   0.02702369]\n",
      " [ 0.02702715  0.02702722  0.02702823 ...,  0.02702667  0.02702729\n",
      "   0.02702368]\n",
      " [ 0.02702711  0.02702728  0.02702825 ...,  0.02702668  0.02702725\n",
      "   0.02702371]]\n",
      "[26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test, batch_size=128, verbose=0)# for dataset of 2 characters\n",
    "print (y_pred)\n",
    "y_pred=numpy.argmax(y_pred, axis=1)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model=Sequential()\n",
    "#y_pred=model.predict_classes(x_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "target=y_test\n",
    "#print (classification_report(numpy.argmax(y_test, axis=1), y_pred, target))\n",
    "print(confusion_matrix(numpy.argmax(y_test, axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pandas.DataFrame(hist.history).to_csv(\"D:Dataset_Final(March)/Checkpoints/Level_1/Epoch_60/Figure/History.csv\")        \n",
    "# visualizing losses and accuracy\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'Solarize_Light2', '_classic_test']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pp=PdfPages(\"D:Dataset_Final(March)/Checkpoints/Level_1/Epoch_60/Figure/Loss.pdf\")\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print (plt.style.available)# use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "plt.savefig(pp, format='pdf')\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp=PdfPages(\"D:Dataset_Final(March)/Checkpoints/Level_1/Epoch_60/Figure/Accuracy.pdf\")\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "plt.savefig(pp, format='pdf')\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliafridi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.33333333,  0.        ]),\n",
       " array([ 0.,  1.,  0.]),\n",
       " array([ 0. ,  0.5,  0. ]),\n",
       " array([1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true=numpy.array(['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19',\n",
    "#                    '20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36'])\n",
    "# y_pred=numpy.array('26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26',\n",
    "#                    '26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26','26')\n",
    "y_true=['1','2','3']\n",
    "y_pred=['2','2','2']\n",
    "precision_recall_fscore_support(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166666666667\n",
      "0.111111111111\n",
      "0.333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliafridi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\aliafridi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (f1_score(y_true, y_pred, average='macro'))\n",
    "print (precision_score(y_true, y_pred, average='macro'))\n",
    "print (recall_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
