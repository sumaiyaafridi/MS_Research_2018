{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "numpy.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumayyah\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, MaxPooling2D, Dropout\n",
    "from keras.layers import Conv2D, Embedding\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "from keras_contrib.layers.advanced_activations import PELU, SReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128 \n",
    "num_classes=37\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:\");\n",
    "path=\"E:/Dataset_Final(March)/One\";\n",
    "classes=os.listdir(path)\n",
    "x=[]#Datapoints \n",
    "y=[]#labels \n",
    "for fol in classes:\n",
    "    imgfiles=os.listdir(path+u'\\\\'+fol);\n",
    "    for img in imgfiles:\n",
    "        im=mpimg.imread(path+u'\\\\'+fol+u'\\\\'+img);\n",
    "        x.append(im)\n",
    "        y.append(fol)\n",
    "x=numpy.array(x)\n",
    "y=numpy.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 100)\n",
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x=x.reshape((-1,100,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=x.shape[0]\n",
    "randomize=numpy.arange(n)\n",
    "numpy.random.shuffle(randomize)\n",
    "randomize\n",
    "x=x[randomize]\n",
    "y=y[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 100, 100, 1)\n",
      "(96,)\n",
      "(48, 100, 100, 1)\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "test_split=round(n*2/3)\n",
    "x_train=x[:test_split]\n",
    "y_train=y[:test_split]\n",
    "x_test=x[test_split:]\n",
    "y_test=y[test_split:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=Input(shape=(100,100,1))\n",
    "# x=Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "# x=SReLU()(x)\n",
    "# x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "# x=Conv2D(16, (3, 3), padding='same')(x)\n",
    "# x=SReLU()(x)\n",
    "# x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# x=Dropout(0.2)(x)#---------------------------------------------->0.5208(Epoch_101)\n",
    "# x=Dense(num_classes)(x)\n",
    "# x=SReLU()(x)\n",
    "# x=Flatten()(x)\n",
    "# x=Dense(num_classes)(x)\n",
    "\n",
    "# output=Activation('softmax')(x)\n",
    "# model=Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=Input(shape=(100,100,1))\n",
    "x=Conv2D(128, (3, 3), padding='same')(inputs)\n",
    "x=SReLU()(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Conv2D(32, (3, 3), padding='same')(x)\n",
    "x=SReLU()(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "# x=Conv2D(7, (3, 3), padding='same')(x)\n",
    "# x=SReLU()(x)\n",
    "# x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x=Dropout(0.2)(x)#---------------------------------------------->0.(Epoch_102)\n",
    "x=Dense(num_classes)(x)\n",
    "x=SReLU()(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(num_classes)(x)\n",
    "\n",
    "output=Activation('softmax')(x)\n",
    "model=Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 100, 100, 128)     1280      \n",
      "_________________________________________________________________\n",
      "s_re_lu_11 (SReLU)           (None, 100, 100, 128)     5120000   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 50, 50, 32)        36896     \n",
      "_________________________________________________________________\n",
      "s_re_lu_12 (SReLU)           (None, 50, 50, 32)        320000    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25, 25, 37)        1221      \n",
      "_________________________________________________________________\n",
      "s_re_lu_13 (SReLU)           (None, 25, 25, 37)        92500     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 23125)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37)                855662    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 6,427,559\n",
      "Trainable params: 6,427,559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=keras.optimizers.Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath='E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-{epoch:2d}-{val_acc:.2f}.hdf5'\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 48 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 1-0.04.hdf5\n",
      "96/96 [==============================] - 42s 437ms/step - loss: 3.6128 - acc: 0.0312 - val_loss: 3.6059 - val_acc: 0.0417\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 2-0.02.hdf5\n",
      "96/96 [==============================] - 34s 354ms/step - loss: 3.5753 - acc: 0.2500 - val_loss: 3.6166 - val_acc: 0.0208\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 3-0.02.hdf5\n",
      "96/96 [==============================] - 34s 356ms/step - loss: 3.5281 - acc: 0.1875 - val_loss: 3.6656 - val_acc: 0.0208\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 4-0.02.hdf5\n",
      "96/96 [==============================] - 34s 358ms/step - loss: 3.4470 - acc: 0.2292 - val_loss: 3.7853 - val_acc: 0.0208\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 5-0.02.hdf5\n",
      "96/96 [==============================] - 35s 360ms/step - loss: 3.3592 - acc: 0.2604 - val_loss: 3.9058 - val_acc: 0.0208\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 6-0.06.hdf5\n",
      "96/96 [==============================] - 37s 389ms/step - loss: 3.2721 - acc: 0.3333 - val_loss: 3.8208 - val_acc: 0.0625\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 7-0.10.hdf5\n",
      "96/96 [==============================] - 37s 386ms/step - loss: 3.1497 - acc: 0.3958 - val_loss: 3.6142 - val_acc: 0.1042\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 8-0.15.hdf5\n",
      "96/96 [==============================] - 34s 354ms/step - loss: 2.9799 - acc: 0.5104 - val_loss: 3.3699 - val_acc: 0.1458\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement- 9-0.21.hdf5\n",
      "96/96 [==============================] - 33s 344ms/step - loss: 2.7913 - acc: 0.5521 - val_loss: 3.1213 - val_acc: 0.2083\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-10-0.23.hdf5\n",
      "96/96 [==============================] - 32s 335ms/step - loss: 2.5924 - acc: 0.5417 - val_loss: 2.8728 - val_acc: 0.2292\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-11-0.23.hdf5\n",
      "96/96 [==============================] - 33s 341ms/step - loss: 2.3397 - acc: 0.5625 - val_loss: 2.6193 - val_acc: 0.2292\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-12-0.23.hdf5\n",
      "96/96 [==============================] - 33s 342ms/step - loss: 2.0776 - acc: 0.5521 - val_loss: 2.3738 - val_acc: 0.2292\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-13-0.27.hdf5\n",
      "96/96 [==============================] - 35s 360ms/step - loss: 1.8129 - acc: 0.5625 - val_loss: 2.1390 - val_acc: 0.2708\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-14-0.27.hdf5\n",
      "96/96 [==============================] - 34s 351ms/step - loss: 1.5620 - acc: 0.6146 - val_loss: 1.8686 - val_acc: 0.2708\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-15-0.42.hdf5\n",
      "96/96 [==============================] - 37s 381ms/step - loss: 1.3426 - acc: 0.5938 - val_loss: 1.5970 - val_acc: 0.4167\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-16-0.42.hdf5\n",
      "96/96 [==============================] - 34s 350ms/step - loss: 1.1739 - acc: 0.6979 - val_loss: 1.3615 - val_acc: 0.4167\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-17-0.46.hdf5\n",
      "96/96 [==============================] - 33s 339ms/step - loss: 1.0649 - acc: 0.6771 - val_loss: 1.2500 - val_acc: 0.4583\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-18-0.46.hdf5\n",
      "96/96 [==============================] - 34s 357ms/step - loss: 0.9383 - acc: 0.6875 - val_loss: 1.2559 - val_acc: 0.4583\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-19-0.46.hdf5\n",
      "96/96 [==============================] - 33s 345ms/step - loss: 0.8584 - acc: 0.6458 - val_loss: 1.2493 - val_acc: 0.4583\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-20-0.46.hdf5\n",
      "96/96 [==============================] - 39s 404ms/step - loss: 0.7878 - acc: 0.6771 - val_loss: 1.1526 - val_acc: 0.4583\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-21-0.50.hdf5\n",
      "96/96 [==============================] - 36s 372ms/step - loss: 0.7349 - acc: 0.7500 - val_loss: 1.0925 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-22-0.50.hdf5\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.6854 - acc: 0.6875 - val_loss: 1.1729 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-23-0.44.hdf5\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.6990 - acc: 0.6771 - val_loss: 1.2011 - val_acc: 0.4375\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-24-0.46.hdf5\n",
      "96/96 [==============================] - 34s 352ms/step - loss: 0.6327 - acc: 0.7188 - val_loss: 1.1223 - val_acc: 0.4583\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-25-0.50.hdf5\n",
      "96/96 [==============================] - 34s 351ms/step - loss: 0.6164 - acc: 0.6875 - val_loss: 1.2018 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-26-0.48.hdf5\n",
      "96/96 [==============================] - 33s 341ms/step - loss: 0.6251 - acc: 0.7083 - val_loss: 1.2254 - val_acc: 0.4792\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-27-0.48.hdf5\n",
      "96/96 [==============================] - 33s 341ms/step - loss: 0.6076 - acc: 0.7083 - val_loss: 1.3448 - val_acc: 0.4792\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-28-0.48.hdf5\n",
      "96/96 [==============================] - 34s 350ms/step - loss: 0.5364 - acc: 0.7292 - val_loss: 1.3005 - val_acc: 0.4792\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-29-0.48.hdf5\n",
      "96/96 [==============================] - 32s 334ms/step - loss: 0.5895 - acc: 0.6875 - val_loss: 1.3083 - val_acc: 0.4792\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-30-0.48.hdf5\n",
      "96/96 [==============================] - 32s 335ms/step - loss: 0.5404 - acc: 0.7500 - val_loss: 1.4580 - val_acc: 0.4792\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-31-0.50.hdf5\n",
      "96/96 [==============================] - 34s 353ms/step - loss: 0.5459 - acc: 0.7188 - val_loss: 1.3612 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-32-0.50.hdf5\n",
      "96/96 [==============================] - 35s 360ms/step - loss: 0.6113 - acc: 0.7083 - val_loss: 1.5198 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-33-0.50.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 33s 346ms/step - loss: 0.6288 - acc: 0.7396 - val_loss: 1.4646 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-34-0.54.hdf5\n",
      "96/96 [==============================] - 32s 332ms/step - loss: 0.5213 - acc: 0.7188 - val_loss: 1.5123 - val_acc: 0.5417\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-35-0.50.hdf5\n",
      "96/96 [==============================] - 34s 350ms/step - loss: 0.5671 - acc: 0.7083 - val_loss: 1.7569 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-36-0.50.hdf5\n",
      "96/96 [==============================] - 33s 349ms/step - loss: 0.5629 - acc: 0.6979 - val_loss: 1.7541 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-37-0.50.hdf5\n",
      "96/96 [==============================] - 33s 341ms/step - loss: 0.6077 - acc: 0.6875 - val_loss: 1.6678 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-38-0.48.hdf5\n",
      "96/96 [==============================] - 35s 363ms/step - loss: 0.5570 - acc: 0.7188 - val_loss: 1.7219 - val_acc: 0.4792\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-39-0.46.hdf5\n",
      "96/96 [==============================] - 34s 359ms/step - loss: 0.5185 - acc: 0.7604 - val_loss: 1.7461 - val_acc: 0.4583\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-40-0.48.hdf5\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.5126 - acc: 0.7396 - val_loss: 1.8511 - val_acc: 0.4792\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-41-0.54.hdf5\n",
      "96/96 [==============================] - 33s 339ms/step - loss: 0.5729 - acc: 0.7083 - val_loss: 1.7973 - val_acc: 0.5417\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-42-0.50.hdf5\n",
      "96/96 [==============================] - 33s 339ms/step - loss: 0.5430 - acc: 0.6979 - val_loss: 1.8076 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-43-0.50.hdf5\n",
      "96/96 [==============================] - 34s 353ms/step - loss: 0.5605 - acc: 0.6875 - val_loss: 1.7350 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-44-0.48.hdf5\n",
      "96/96 [==============================] - 35s 367ms/step - loss: 0.5520 - acc: 0.7500 - val_loss: 1.7569 - val_acc: 0.4792\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-45-0.48.hdf5\n",
      "96/96 [==============================] - 33s 348ms/step - loss: 0.5291 - acc: 0.7396 - val_loss: 1.7486 - val_acc: 0.4792\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-46-0.52.hdf5\n",
      "96/96 [==============================] - 34s 356ms/step - loss: 0.5607 - acc: 0.6875 - val_loss: 1.7774 - val_acc: 0.5208\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-47-0.48.hdf5\n",
      "96/96 [==============================] - 33s 344ms/step - loss: 0.5323 - acc: 0.7083 - val_loss: 1.8622 - val_acc: 0.4792\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-48-0.48.hdf5\n",
      "96/96 [==============================] - 33s 339ms/step - loss: 0.5270 - acc: 0.7396 - val_loss: 1.8930 - val_acc: 0.4792\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-49-0.48.hdf5\n",
      "96/96 [==============================] - 33s 344ms/step - loss: 0.5511 - acc: 0.6875 - val_loss: 1.8635 - val_acc: 0.4792\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-50-0.48.hdf5\n",
      "96/96 [==============================] - 33s 339ms/step - loss: 0.5086 - acc: 0.7083 - val_loss: 1.7962 - val_acc: 0.4792\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-51-0.48.hdf5\n",
      "96/96 [==============================] - 34s 359ms/step - loss: 0.5299 - acc: 0.7500 - val_loss: 1.8152 - val_acc: 0.4792\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-52-0.48.hdf5\n",
      "96/96 [==============================] - 32s 336ms/step - loss: 0.5241 - acc: 0.7396 - val_loss: 1.8733 - val_acc: 0.4792\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-53-0.48.hdf5\n",
      "96/96 [==============================] - 33s 341ms/step - loss: 0.5545 - acc: 0.7396 - val_loss: 1.8909 - val_acc: 0.4792\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-54-0.48.hdf5\n",
      "96/96 [==============================] - 34s 352ms/step - loss: 0.5386 - acc: 0.7188 - val_loss: 1.9219 - val_acc: 0.4792\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-55-0.50.hdf5\n",
      "96/96 [==============================] - 33s 342ms/step - loss: 0.5071 - acc: 0.7292 - val_loss: 1.9397 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-56-0.50.hdf5\n",
      "96/96 [==============================] - 37s 384ms/step - loss: 0.5428 - acc: 0.7500 - val_loss: 1.9359 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-57-0.50.hdf5\n",
      "96/96 [==============================] - 33s 346ms/step - loss: 0.5047 - acc: 0.7396 - val_loss: 1.8447 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: saving model to E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_102/weights-improvement-58-0.50.hdf5\n",
      "96/96 [==============================] - 34s 356ms/step - loss: 0.5192 - acc: 0.6979 - val_loss: 1.7679 - val_acc: 0.5000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[96,100,100,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select = Select[T=DT_FLOAT, _class=[\"loc:@s_re_lu_11/LeakyRelu/Maximum\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/GreaterEqual, training_3/Adam/gradients/s_re_lu_11/Minimum_grad/Reshape, training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select', defined at:\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-876c02652090>\", line 5, in <module>\n    callbacks=[checkpoint]\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\optimizers.py\", line 434, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 375, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 904, in _MaximumGrad\n    return _MaximumMinimumGrad(op, grad, math_ops.greater_equal)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 894, in _MaximumMinimumGrad\n    xgrad = array_ops.where(xmask, grad, zeros)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2540, in where\n    return gen_math_ops._select(condition=condition, x=x, y=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4528, in _select\n    \"Select\", condition=condition, t=x, e=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 's_re_lu_11/LeakyRelu/Maximum', defined at:\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-0d2f2276bec7>\", line 3, in <module>\n    x=SReLU()(x)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras_contrib\\layers\\advanced_activations.py\", line 223, in call\n    t_right_actual - t_left)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2918, in relu\n    x = tf.nn.leaky_relu(x, alpha)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1548, in leaky_relu\n    return math_ops.maximum(alpha * features, features)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2887, in maximum\n    \"Maximum\", x=x, y=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[96,100,100,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select = Select[T=DT_FLOAT, _class=[\"loc:@s_re_lu_11/LeakyRelu/Maximum\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/GreaterEqual, training_3/Adam/gradients/s_re_lu_11/Minimum_grad/Reshape, training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[96,100,100,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select = Select[T=DT_FLOAT, _class=[\"loc:@s_re_lu_11/LeakyRelu/Maximum\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/GreaterEqual, training_3/Adam/gradients/s_re_lu_11/Minimum_grad/Reshape, training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-876c02652090>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                )\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[96,100,100,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select = Select[T=DT_FLOAT, _class=[\"loc:@s_re_lu_11/LeakyRelu/Maximum\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/GreaterEqual, training_3/Adam/gradients/s_re_lu_11/Minimum_grad/Reshape, training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select', defined at:\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-876c02652090>\", line 5, in <module>\n    callbacks=[checkpoint]\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\optimizers.py\", line 434, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 375, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 904, in _MaximumGrad\n    return _MaximumMinimumGrad(op, grad, math_ops.greater_equal)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 894, in _MaximumMinimumGrad\n    xgrad = array_ops.where(xmask, grad, zeros)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 2540, in where\n    return gen_math_ops._select(condition=condition, x=x, y=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4528, in _select\n    \"Select\", condition=condition, t=x, e=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 's_re_lu_11/LeakyRelu/Maximum', defined at:\n  File \"e:\\anaconda3\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-0d2f2276bec7>\", line 3, in <module>\n    x=SReLU()(x)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras_contrib\\layers\\advanced_activations.py\", line 223, in call\n    t_right_actual - t_left)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2918, in relu\n    x = tf.nn.leaky_relu(x, alpha)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1548, in leaky_relu\n    return math_ops.maximum(alpha * features, features)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2887, in maximum\n    \"Maximum\", x=x, y=y, name=name)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"c:\\users\\sumayyah\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[96,100,100,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/Select = Select[T=DT_FLOAT, _class=[\"loc:@s_re_lu_11/LeakyRelu/Maximum\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/GreaterEqual, training_3/Adam/gradients/s_re_lu_11/Minimum_grad/Reshape, training_3/Adam/gradients/s_re_lu_11/LeakyRelu/Maximum_grad/zeros)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x_train, y_train, \n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_test),\n",
    "               callbacks=[checkpoint]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.94713150e-15 2.14662532e-09 1.70969159e-11 ... 2.00195354e-03\n",
      "  9.19864007e-08 2.72958427e-11]\n",
      " [4.48768135e-15 3.68956316e-05 1.37981804e-08 ... 5.73652287e-05\n",
      "  2.21351511e-04 4.90789603e-07]\n",
      " [1.10384114e-14 7.62660534e-07 1.29510340e-07 ... 3.51367760e-07\n",
      "  9.98131216e-01 2.39886688e-08]\n",
      " ...\n",
      " [1.91567767e-14 1.10330063e-06 2.05815184e-07 ... 1.10503755e-07\n",
      "  9.99504924e-01 6.21020106e-08]\n",
      " [1.25344591e-18 1.22945255e-15 7.21911967e-01 ... 5.30969366e-11\n",
      "  1.54337473e-10 2.29286812e-10]\n",
      " [3.09989243e-18 3.21937233e-14 3.30994339e-06 ... 7.24031557e-10\n",
      "  1.42700865e-10 3.47372586e-12]]\n",
      "[16 11 35  2  4  4 27 31 30 25 10 36 25 22  8 13 16 25 22 21  3 34 28 34\n",
      " 11 29 22 24 26 32 33 25 10 16  8 30 16  4 16  8  8 13 26 29 28 35  2 30]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)# for dataset of 12 characters\n",
    "print (y_pred)\n",
    "y_pred=numpy.argmax(y_pred, axis=1)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_101/weights-improvement-83-0.50.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.9533046e-16 8.5169066e-10 6.3168598e-12 ... 8.2372007e-04\n",
      "  7.1592382e-08 1.3190575e-11]\n",
      " [1.2177702e-15 1.7118555e-05 5.6550387e-09 ... 2.4719671e-05\n",
      "  2.4708713e-04 3.1102670e-07]\n",
      " [2.8961037e-15 3.3115674e-07 5.2287238e-08 ... 1.5821681e-07\n",
      "  9.9826235e-01 1.4393768e-08]\n",
      " ...\n",
      " [5.0124640e-15 5.0098419e-07 8.1451283e-08 ... 4.7955403e-08\n",
      "  9.9955052e-01 3.7837570e-08]\n",
      " [2.8464851e-19 4.5182924e-16 3.6656675e-01 ... 9.7701751e-12\n",
      "  1.2010790e-10 1.6493006e-10]\n",
      " [1.3667511e-18 2.1992745e-14 2.0391437e-06 ... 3.2368427e-10\n",
      "  2.0967901e-10 3.6468849e-12]]\n",
      "[16 11 35  2  4  4 27 31 30 25  7 36 25 22  8 13 16 25 22 21  3 34 29 34\n",
      " 11 29 22 24 26 32 33 25  7 16  8 30 16  5 16  8  8 13 26 29 28 35  3 30]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)# for dataset of 12 characters\n",
    "print (y_pred)\n",
    "y_pred=numpy.argmax(y_pred, axis=1)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(numpy.argmax(y_test, axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       1.00      1.00      1.00         1\n",
      "          3       1.00      1.00      1.00         2\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.25      0.50      0.33         2\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.00         1\n",
      "         11       0.00      0.00      0.00         2\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       0.00      0.00      0.00         3\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         1\n",
      "         21       0.00      0.00      0.00         0\n",
      "         22       0.33      1.00      0.50         1\n",
      "         23       0.00      0.00      0.00         2\n",
      "         24       1.00      0.33      0.50         3\n",
      "         25       0.50      1.00      0.67         2\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       1.00      0.50      0.67         2\n",
      "         29       0.67      1.00      0.80         2\n",
      "         30       1.00      1.00      1.00         3\n",
      "         31       1.00      1.00      1.00         1\n",
      "         32       0.00      0.00      0.00         0\n",
      "         33       1.00      0.50      0.67         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.52      0.50      0.48        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumayyah\\keras\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\sumayyah\\keras\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (classification_report(numpy.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pandas.DataFrame(hist.history).to_csv(\"E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_101/Figure/History.csv\")        \n",
    "# visualizing losses and accuracy\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'Solarize_Light2', '_classic_test']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pp=PdfPages(\"E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_101/Figure/Loss.pdf\")\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print (plt.style.available)\n",
    "plt.style.use(['classic'])\n",
    "plt.savefig(pp, format='pdf')\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e735cf9748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp=PdfPages(\"E:Dataset_Final(March)/Checkpoints/Level_1/Epoch_101/Figure/Accuracy.pdf\")\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "plt.savefig(pp, format='pdf')\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
